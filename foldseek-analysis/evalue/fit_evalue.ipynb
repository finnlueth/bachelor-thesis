{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fit_evalue.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#MMSEQS_FORCE_MERGE=1 foldseek/build/src/foldseek search 100k_sample 20k_random_sample_foldseek_shuffled 100k_random_sample_foldseek_shuffled_aln tmp -e 10000000 -s 9 --max-seqs 2000 --threads 128\n",
        "##!/bin/bash\n",
        "#INFILE=\"100k_random_sample_foldseek_shuffled_aln.m8\"\n",
        "\n",
        "\n",
        "#while read line; do\n",
        "#  seq=$(echo $line| cut -d';' -f1)\n",
        "#  score=$(echo $line| cut -d';' -f2)\n",
        "#  if [ $(awk -F \",\" '{print NF-1}' <(echo $score)) -gt 10 ]\n",
        "#  then\n",
        "#          echo $seq\" \"$(./fiteval $score)\n",
        "#  fi\n",
        "#done < <(awk '$1!=prev{print seq\";\"score; score=\"\"; seq=\"\"}  {if(score!=\"\"){score=score\",\"$(NF-1)}else{score=$(NF-1)}; seq=$NF; prev=$1;}' 100k_random_sample_foldseek_shuffled_aln.m8)\n",
        "#awk 'BEGIN{print \"seq;lambda;mu\"}{gsub(\"lamda=\",\"\",$2); gsub(\"mu=\",\"\",$3); print $1\";\"$2\";\"$3}'  100k_per_query_mu_lambda.m8 > 100k_per_query_mu_lambda.csv\n",
        "\n"
      ],
      "metadata": {
        "id": "C19_vJkBGf2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1PXfGT6sBgd",
        "outputId": "79fa5bde-6e51-42b9-c644-60450415df13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 37.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 3.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RRTFkCkFZhf3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dropout \n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# read csv file having three columns: seq as str, lambda as float, and mu as float\n",
        "def prepare_input(filename):\n",
        "    data = np.genfromtxt(filename, delimiter=';', skip_header=1, dtype=str)\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(0, len(data)):\n",
        "        kmers = string_to_kmers(data[i][0], 2)\n",
        "        counts1mer = add_1mer_counts(data[i][0])\n",
        "        counts = np.append(counts1mer, [len(data[i][0])])\n",
        "        #counts2mer = add_2mer_counts(kmers)\n",
        "        #counts = np.append(counts1mer, counts2mer) \n",
        "        # append sequence length to counts\n",
        "        #counts = np.append(counts, [len(data[i][0])])\n",
        "        X.append(counts)\n",
        "        y.append([float(data[i][1]), float(data[i][2])])\n",
        "    return np.asarray(X), np.asarray(y)\n",
        "\n",
        "# turn string into k-mers\n",
        "def string_to_kmers(string, k):\n",
        "    kmers = []\n",
        "    for i in range(0, len(string) - k + 1, k):\n",
        "        kmers.append(string[i:i+k])\n",
        "    return kmers\n",
        "\n",
        "# map of 20 amino acids (alphabetically) and X to integers\n",
        "def map_to_int(amino_acid):\n",
        "    alphabet = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'X']\n",
        "    return alphabet.index(amino_acid)\n",
        "\n",
        "def add_1mer_counts(string):\n",
        "  counts = np.zeros(21)\n",
        "  for i in range(0, len(string)): \n",
        "    counts[map_to_int(string[i])] += 1\n",
        "  return counts\n",
        "\n",
        "# add 2-mer 21*21 integers\n",
        "def add_2mer_counts(kmers):\n",
        "    counts = np.zeros((21, 21))\n",
        "    for kmer in kmers:\n",
        "        counts[map_to_int(kmer[0])][map_to_int(kmer[1])] += 1\n",
        "    return counts\n",
        "\n",
        "# normalize Y values \n",
        "def normalize_y(y):\n",
        "    y_norm = np.copy(y)\n",
        "    mu1 = np.mean(y[:,0])\n",
        "    sigma1 = np.std(y[:,0])\n",
        "    mu2 = np.mean(y[:,1])\n",
        "    sigma2 = np.std(y[:,1])\n",
        "    for i in range(0, len(y)):\n",
        "        y_norm[i][0] = (y[i][0] - mu1) / sigma1\n",
        "        y_norm[i][1] = (y[i][1] - mu2) / sigma2\n",
        "    return y_norm, mu1, sigma1, mu2, sigma2\n",
        "\n",
        "\n",
        "def unnormalize_y(y_norm, mu1, sigma1, mu2, sigma2):\n",
        "    y = np.copy(y_norm)\n",
        "    for i in range(0, len(y)):\n",
        "        y[i][0] = y_norm[i][0] * sigma1 + mu1\n",
        "        y[i][1] = y_norm[i][1] * sigma2 + mu2\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y = prepare_input('/content/drive/MyDrive/100k_per_query_mu_lambda.csv')\n",
        "Y_norm, mu1, sigma1, mu2, sigma2 = normalize_y(Y)\n",
        "#Y_norm, min1, max1, min2, max2 = normalize_y_2(Y)"
      ],
      "metadata": {
        "id": "Ris03C0gGZYZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "# keras model with k-mer and seq len as input and two output nodes for regression\n",
        "# Predict mu and lambda\n",
        "def keras_model(hp):\n",
        "    model = Sequential()\n",
        "    hp_units = hp.Int('units', min_value=16, max_value=48, step=16)\n",
        "    model.add(Dense(units=hp_units, activation=\"relu\", input_shape=(22,)))\n",
        "    layer_units = hp.Int('layer', min_value=0, max_value=2, step=1)\n",
        "    for i in range(layer_units):\n",
        "      model.add(Dense(units=hp_units, activation=\"relu\"))\n",
        "    model.add(Dense(units=2))\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5])  \n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(keras_model,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=40,\n",
        "                     factor=5,\n",
        "                     directory='my_dir',\n",
        "                     project_name='opt_hp_param_input22_simple3')\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "tuner.search(X, Y_norm, epochs=100, validation_split=0.2, callbacks=[stop_early])\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. \n",
        "Ynits: {best_hps.get('units')} Layer: {best_hps.get('layer')} :earning rate: {best_hps.get('learning_rate')}.\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "#model = keras_model(X[0].shape, Y_norm[0].shape[0], 2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLri_tCrGZ3h",
        "outputId": "c18e2d98-0ef6-4951-9462-4c0ae9b37b3b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 48 Complete [00h 00m 52s]\n",
            "val_accuracy: 0.9072861075401306\n",
            "\n",
            "Best val_accuracy So Far: 0.9180377125740051\n",
            "Total elapsed time: 00h 21m 06s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "\n",
            "The hyperparameter search is complete. \n",
            "Ynits: 32 Layer: 2 :earning rate: 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X, Y_norm, epochs=100, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))\n",
        "\n",
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "# Retrain the model\n",
        "hypermodel.fit(X, Y_norm, epochs=best_epoch, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7pzyp9ZnRQd",
        "outputId": "e24d02e2-b737-4d40-84f4-ff27588396a5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 4.1716 - accuracy: 0.7470 - val_loss: 0.5745 - val_accuracy: 0.7363\n",
            "Epoch 2/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.7157 - accuracy: 0.7995 - val_loss: 1.0602 - val_accuracy: 0.7440\n",
            "Epoch 3/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.4875 - accuracy: 0.8291 - val_loss: 0.4033 - val_accuracy: 0.8849\n",
            "Epoch 4/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.3075 - accuracy: 0.8673 - val_loss: 0.2430 - val_accuracy: 0.8915\n",
            "Epoch 5/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.2251 - accuracy: 0.8933 - val_loss: 0.1793 - val_accuracy: 0.8999\n",
            "Epoch 6/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1753 - accuracy: 0.9031 - val_loss: 0.1907 - val_accuracy: 0.8981\n",
            "Epoch 7/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1479 - accuracy: 0.9053 - val_loss: 0.1445 - val_accuracy: 0.9084\n",
            "Epoch 8/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1393 - accuracy: 0.9053 - val_loss: 0.1311 - val_accuracy: 0.9097\n",
            "Epoch 9/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1334 - accuracy: 0.9068 - val_loss: 0.1266 - val_accuracy: 0.9079\n",
            "Epoch 10/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1302 - accuracy: 0.9083 - val_loss: 0.1296 - val_accuracy: 0.9044\n",
            "Epoch 11/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1261 - accuracy: 0.9098 - val_loss: 0.1284 - val_accuracy: 0.9066\n",
            "Epoch 12/100\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1238 - accuracy: 0.9106 - val_loss: 0.1367 - val_accuracy: 0.9042\n",
            "Epoch 13/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1223 - accuracy: 0.9117 - val_loss: 0.1162 - val_accuracy: 0.9145\n",
            "Epoch 14/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1205 - accuracy: 0.9115 - val_loss: 0.1194 - val_accuracy: 0.9144\n",
            "Epoch 15/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1196 - accuracy: 0.9113 - val_loss: 0.1164 - val_accuracy: 0.9123\n",
            "Epoch 16/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1189 - accuracy: 0.9132 - val_loss: 0.1166 - val_accuracy: 0.9146\n",
            "Epoch 17/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1180 - accuracy: 0.9130 - val_loss: 0.1137 - val_accuracy: 0.9146\n",
            "Epoch 18/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1165 - accuracy: 0.9134 - val_loss: 0.1213 - val_accuracy: 0.9125\n",
            "Epoch 19/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1158 - accuracy: 0.9142 - val_loss: 0.1139 - val_accuracy: 0.9146\n",
            "Epoch 20/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1151 - accuracy: 0.9138 - val_loss: 0.1162 - val_accuracy: 0.9120\n",
            "Epoch 21/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1145 - accuracy: 0.9137 - val_loss: 0.1120 - val_accuracy: 0.9143\n",
            "Epoch 22/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1140 - accuracy: 0.9139 - val_loss: 0.1091 - val_accuracy: 0.9169\n",
            "Epoch 23/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1130 - accuracy: 0.9157 - val_loss: 0.1127 - val_accuracy: 0.9144\n",
            "Epoch 24/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1123 - accuracy: 0.9148 - val_loss: 0.1102 - val_accuracy: 0.9160\n",
            "Epoch 25/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1121 - accuracy: 0.9154 - val_loss: 0.1109 - val_accuracy: 0.9146\n",
            "Epoch 26/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1115 - accuracy: 0.9156 - val_loss: 0.1149 - val_accuracy: 0.9156\n",
            "Epoch 27/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1108 - accuracy: 0.9160 - val_loss: 0.1093 - val_accuracy: 0.9164\n",
            "Epoch 28/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1107 - accuracy: 0.9163 - val_loss: 0.1119 - val_accuracy: 0.9159\n",
            "Epoch 29/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1102 - accuracy: 0.9158 - val_loss: 0.1087 - val_accuracy: 0.9177\n",
            "Epoch 30/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1103 - accuracy: 0.9161 - val_loss: 0.1101 - val_accuracy: 0.9151\n",
            "Epoch 31/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1097 - accuracy: 0.9168 - val_loss: 0.1105 - val_accuracy: 0.9145\n",
            "Epoch 32/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1092 - accuracy: 0.9172 - val_loss: 0.1170 - val_accuracy: 0.9120\n",
            "Epoch 33/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1093 - accuracy: 0.9166 - val_loss: 0.1113 - val_accuracy: 0.9147\n",
            "Epoch 34/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1088 - accuracy: 0.9169 - val_loss: 0.1164 - val_accuracy: 0.9113\n",
            "Epoch 35/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1088 - accuracy: 0.9172 - val_loss: 0.1152 - val_accuracy: 0.9144\n",
            "Epoch 36/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1087 - accuracy: 0.9169 - val_loss: 0.1078 - val_accuracy: 0.9177\n",
            "Epoch 37/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1083 - accuracy: 0.9172 - val_loss: 0.1056 - val_accuracy: 0.9185\n",
            "Epoch 38/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1080 - accuracy: 0.9173 - val_loss: 0.1080 - val_accuracy: 0.9164\n",
            "Epoch 39/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1082 - accuracy: 0.9176 - val_loss: 0.1055 - val_accuracy: 0.9191\n",
            "Epoch 40/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1081 - accuracy: 0.9171 - val_loss: 0.1098 - val_accuracy: 0.9166\n",
            "Epoch 41/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1075 - accuracy: 0.9182 - val_loss: 0.1062 - val_accuracy: 0.9185\n",
            "Epoch 42/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1075 - accuracy: 0.9173 - val_loss: 0.1061 - val_accuracy: 0.9169\n",
            "Epoch 43/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1076 - accuracy: 0.9177 - val_loss: 0.1092 - val_accuracy: 0.9159\n",
            "Epoch 44/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1076 - accuracy: 0.9180 - val_loss: 0.1085 - val_accuracy: 0.9132\n",
            "Epoch 45/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1072 - accuracy: 0.9177 - val_loss: 0.1080 - val_accuracy: 0.9179\n",
            "Epoch 46/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1071 - accuracy: 0.9184 - val_loss: 0.1076 - val_accuracy: 0.9159\n",
            "Epoch 47/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1068 - accuracy: 0.9178 - val_loss: 0.1066 - val_accuracy: 0.9168\n",
            "Epoch 48/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1071 - accuracy: 0.9177 - val_loss: 0.1101 - val_accuracy: 0.9156\n",
            "Epoch 49/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1066 - accuracy: 0.9186 - val_loss: 0.1088 - val_accuracy: 0.9165\n",
            "Epoch 50/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1071 - accuracy: 0.9183 - val_loss: 0.1045 - val_accuracy: 0.9194\n",
            "Epoch 51/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1064 - accuracy: 0.9182 - val_loss: 0.1078 - val_accuracy: 0.9169\n",
            "Epoch 52/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1067 - accuracy: 0.9180 - val_loss: 0.1079 - val_accuracy: 0.9148\n",
            "Epoch 53/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1062 - accuracy: 0.9183 - val_loss: 0.1093 - val_accuracy: 0.9152\n",
            "Epoch 54/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1064 - accuracy: 0.9183 - val_loss: 0.1064 - val_accuracy: 0.9194\n",
            "Epoch 55/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1064 - accuracy: 0.9176 - val_loss: 0.1085 - val_accuracy: 0.9196\n",
            "Epoch 56/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1067 - accuracy: 0.9184 - val_loss: 0.1060 - val_accuracy: 0.9179\n",
            "Epoch 57/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1065 - accuracy: 0.9187 - val_loss: 0.1061 - val_accuracy: 0.9170\n",
            "Epoch 58/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1059 - accuracy: 0.9185 - val_loss: 0.1078 - val_accuracy: 0.9180\n",
            "Epoch 59/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1059 - accuracy: 0.9198 - val_loss: 0.1044 - val_accuracy: 0.9169\n",
            "Epoch 60/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1063 - accuracy: 0.9190 - val_loss: 0.1044 - val_accuracy: 0.9158\n",
            "Epoch 61/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1059 - accuracy: 0.9186 - val_loss: 0.1048 - val_accuracy: 0.9181\n",
            "Epoch 62/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1060 - accuracy: 0.9184 - val_loss: 0.1055 - val_accuracy: 0.9170\n",
            "Epoch 63/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1057 - accuracy: 0.9190 - val_loss: 0.1058 - val_accuracy: 0.9162\n",
            "Epoch 64/100\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1061 - accuracy: 0.9184 - val_loss: 0.1073 - val_accuracy: 0.9171\n",
            "Epoch 65/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1058 - accuracy: 0.9183 - val_loss: 0.1071 - val_accuracy: 0.9140\n",
            "Epoch 66/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1058 - accuracy: 0.9195 - val_loss: 0.1060 - val_accuracy: 0.9178\n",
            "Epoch 67/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1056 - accuracy: 0.9189 - val_loss: 0.1092 - val_accuracy: 0.9163\n",
            "Epoch 68/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1059 - accuracy: 0.9178 - val_loss: 0.1080 - val_accuracy: 0.9161\n",
            "Epoch 69/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1055 - accuracy: 0.9185 - val_loss: 0.1047 - val_accuracy: 0.9185\n",
            "Epoch 70/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1056 - accuracy: 0.9191 - val_loss: 0.1093 - val_accuracy: 0.9183\n",
            "Epoch 71/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1055 - accuracy: 0.9188 - val_loss: 0.1050 - val_accuracy: 0.9183\n",
            "Epoch 72/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1053 - accuracy: 0.9184 - val_loss: 0.1054 - val_accuracy: 0.9192\n",
            "Epoch 73/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1054 - accuracy: 0.9188 - val_loss: 0.1110 - val_accuracy: 0.9160\n",
            "Epoch 74/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1055 - accuracy: 0.9192 - val_loss: 0.1062 - val_accuracy: 0.9200\n",
            "Epoch 75/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1053 - accuracy: 0.9191 - val_loss: 0.1048 - val_accuracy: 0.9164\n",
            "Epoch 76/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1052 - accuracy: 0.9187 - val_loss: 0.1056 - val_accuracy: 0.9163\n",
            "Epoch 77/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1054 - accuracy: 0.9190 - val_loss: 0.1082 - val_accuracy: 0.9186\n",
            "Epoch 78/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1055 - accuracy: 0.9181 - val_loss: 0.1043 - val_accuracy: 0.9173\n",
            "Epoch 79/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1051 - accuracy: 0.9189 - val_loss: 0.1079 - val_accuracy: 0.9186\n",
            "Epoch 80/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1053 - accuracy: 0.9194 - val_loss: 0.1078 - val_accuracy: 0.9154\n",
            "Epoch 81/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1050 - accuracy: 0.9192 - val_loss: 0.1102 - val_accuracy: 0.9179\n",
            "Epoch 82/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1052 - accuracy: 0.9192 - val_loss: 0.1045 - val_accuracy: 0.9174\n",
            "Epoch 83/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1052 - accuracy: 0.9183 - val_loss: 0.1047 - val_accuracy: 0.9159\n",
            "Epoch 84/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1049 - accuracy: 0.9194 - val_loss: 0.1047 - val_accuracy: 0.9169\n",
            "Epoch 85/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1052 - accuracy: 0.9196 - val_loss: 0.1095 - val_accuracy: 0.9154\n",
            "Epoch 86/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1050 - accuracy: 0.9193 - val_loss: 0.1070 - val_accuracy: 0.9171\n",
            "Epoch 87/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1051 - accuracy: 0.9180 - val_loss: 0.1038 - val_accuracy: 0.9182\n",
            "Epoch 88/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1051 - accuracy: 0.9187 - val_loss: 0.1062 - val_accuracy: 0.9183\n",
            "Epoch 89/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1052 - accuracy: 0.9189 - val_loss: 0.1046 - val_accuracy: 0.9174\n",
            "Epoch 90/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1049 - accuracy: 0.9187 - val_loss: 0.1069 - val_accuracy: 0.9178\n",
            "Epoch 91/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1049 - accuracy: 0.9179 - val_loss: 0.1034 - val_accuracy: 0.9194\n",
            "Epoch 92/100\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1048 - accuracy: 0.9192 - val_loss: 0.1065 - val_accuracy: 0.9178\n",
            "Epoch 93/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1049 - accuracy: 0.9190 - val_loss: 0.1033 - val_accuracy: 0.9172\n",
            "Epoch 94/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1045 - accuracy: 0.9191 - val_loss: 0.1064 - val_accuracy: 0.9181\n",
            "Epoch 95/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1050 - accuracy: 0.9192 - val_loss: 0.1038 - val_accuracy: 0.9174\n",
            "Epoch 96/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1047 - accuracy: 0.9189 - val_loss: 0.1072 - val_accuracy: 0.9167\n",
            "Epoch 97/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1047 - accuracy: 0.9192 - val_loss: 0.1091 - val_accuracy: 0.9149\n",
            "Epoch 98/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1048 - accuracy: 0.9188 - val_loss: 0.1055 - val_accuracy: 0.9186\n",
            "Epoch 99/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1048 - accuracy: 0.9185 - val_loss: 0.1092 - val_accuracy: 0.9163\n",
            "Epoch 100/100\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1047 - accuracy: 0.9182 - val_loss: 0.1056 - val_accuracy: 0.9196\n",
            "Best epoch: 74\n",
            "Epoch 1/74\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 9.8498 - accuracy: 0.7186 - val_loss: 0.6675 - val_accuracy: 0.7291\n",
            "Epoch 2/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8623 - accuracy: 0.7743 - val_loss: 0.6206 - val_accuracy: 0.7517\n",
            "Epoch 3/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.6854 - accuracy: 0.8048 - val_loss: 0.4672 - val_accuracy: 0.8867\n",
            "Epoch 4/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.4720 - accuracy: 0.8362 - val_loss: 0.3321 - val_accuracy: 0.8938\n",
            "Epoch 5/74\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 0.2666 - accuracy: 0.8831 - val_loss: 0.1883 - val_accuracy: 0.9005\n",
            "Epoch 6/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1906 - accuracy: 0.8986 - val_loss: 0.1915 - val_accuracy: 0.8953\n",
            "Epoch 7/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1575 - accuracy: 0.9026 - val_loss: 0.1452 - val_accuracy: 0.9111\n",
            "Epoch 8/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1412 - accuracy: 0.9063 - val_loss: 0.1356 - val_accuracy: 0.9089\n",
            "Epoch 9/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1320 - accuracy: 0.9090 - val_loss: 0.1311 - val_accuracy: 0.9061\n",
            "Epoch 10/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1258 - accuracy: 0.9112 - val_loss: 0.1244 - val_accuracy: 0.9071\n",
            "Epoch 11/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1228 - accuracy: 0.9114 - val_loss: 0.1301 - val_accuracy: 0.9106\n",
            "Epoch 12/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1214 - accuracy: 0.9125 - val_loss: 0.1159 - val_accuracy: 0.9145\n",
            "Epoch 13/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1198 - accuracy: 0.9131 - val_loss: 0.1153 - val_accuracy: 0.9130\n",
            "Epoch 14/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1188 - accuracy: 0.9127 - val_loss: 0.1179 - val_accuracy: 0.9131\n",
            "Epoch 15/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1171 - accuracy: 0.9133 - val_loss: 0.1174 - val_accuracy: 0.9120\n",
            "Epoch 16/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1172 - accuracy: 0.9129 - val_loss: 0.1116 - val_accuracy: 0.9153\n",
            "Epoch 17/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1158 - accuracy: 0.9141 - val_loss: 0.1129 - val_accuracy: 0.9152\n",
            "Epoch 18/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1152 - accuracy: 0.9134 - val_loss: 0.1127 - val_accuracy: 0.9143\n",
            "Epoch 19/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1141 - accuracy: 0.9143 - val_loss: 0.1128 - val_accuracy: 0.9136\n",
            "Epoch 20/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1135 - accuracy: 0.9145 - val_loss: 0.1143 - val_accuracy: 0.9139\n",
            "Epoch 21/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1135 - accuracy: 0.9152 - val_loss: 0.1098 - val_accuracy: 0.9137\n",
            "Epoch 22/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1130 - accuracy: 0.9148 - val_loss: 0.1122 - val_accuracy: 0.9136\n",
            "Epoch 23/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1126 - accuracy: 0.9152 - val_loss: 0.1118 - val_accuracy: 0.9172\n",
            "Epoch 24/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1115 - accuracy: 0.9147 - val_loss: 0.1164 - val_accuracy: 0.9124\n",
            "Epoch 25/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1117 - accuracy: 0.9158 - val_loss: 0.1087 - val_accuracy: 0.9152\n",
            "Epoch 26/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1117 - accuracy: 0.9153 - val_loss: 0.1098 - val_accuracy: 0.9170\n",
            "Epoch 27/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1112 - accuracy: 0.9153 - val_loss: 0.1091 - val_accuracy: 0.9176\n",
            "Epoch 28/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1109 - accuracy: 0.9158 - val_loss: 0.1109 - val_accuracy: 0.9137\n",
            "Epoch 29/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1107 - accuracy: 0.9159 - val_loss: 0.1133 - val_accuracy: 0.9168\n",
            "Epoch 30/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1105 - accuracy: 0.9146 - val_loss: 0.1069 - val_accuracy: 0.9179\n",
            "Epoch 31/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1106 - accuracy: 0.9155 - val_loss: 0.1098 - val_accuracy: 0.9144\n",
            "Epoch 32/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1099 - accuracy: 0.9162 - val_loss: 0.1126 - val_accuracy: 0.9169\n",
            "Epoch 33/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1101 - accuracy: 0.9159 - val_loss: 0.1098 - val_accuracy: 0.9156\n",
            "Epoch 34/74\n",
            "2500/2500 [==============================] - 7s 3ms/step - loss: 0.1099 - accuracy: 0.9155 - val_loss: 0.1071 - val_accuracy: 0.9159\n",
            "Epoch 35/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1096 - accuracy: 0.9166 - val_loss: 0.1083 - val_accuracy: 0.9163\n",
            "Epoch 36/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1098 - accuracy: 0.9160 - val_loss: 0.1111 - val_accuracy: 0.9154\n",
            "Epoch 37/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1092 - accuracy: 0.9164 - val_loss: 0.1093 - val_accuracy: 0.9138\n",
            "Epoch 38/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1090 - accuracy: 0.9159 - val_loss: 0.1062 - val_accuracy: 0.9167\n",
            "Epoch 39/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1090 - accuracy: 0.9166 - val_loss: 0.1089 - val_accuracy: 0.9172\n",
            "Epoch 40/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1089 - accuracy: 0.9158 - val_loss: 0.1111 - val_accuracy: 0.9151\n",
            "Epoch 41/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1085 - accuracy: 0.9167 - val_loss: 0.1063 - val_accuracy: 0.9174\n",
            "Epoch 42/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1088 - accuracy: 0.9156 - val_loss: 0.1154 - val_accuracy: 0.9115\n",
            "Epoch 43/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1088 - accuracy: 0.9162 - val_loss: 0.1121 - val_accuracy: 0.9135\n",
            "Epoch 44/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1085 - accuracy: 0.9173 - val_loss: 0.1075 - val_accuracy: 0.9150\n",
            "Epoch 45/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1083 - accuracy: 0.9168 - val_loss: 0.1074 - val_accuracy: 0.9172\n",
            "Epoch 46/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1087 - accuracy: 0.9164 - val_loss: 0.1071 - val_accuracy: 0.9189\n",
            "Epoch 47/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1080 - accuracy: 0.9173 - val_loss: 0.1069 - val_accuracy: 0.9196\n",
            "Epoch 48/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1083 - accuracy: 0.9168 - val_loss: 0.1077 - val_accuracy: 0.9159\n",
            "Epoch 49/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1079 - accuracy: 0.9163 - val_loss: 0.1093 - val_accuracy: 0.9163\n",
            "Epoch 50/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1079 - accuracy: 0.9170 - val_loss: 0.1115 - val_accuracy: 0.9138\n",
            "Epoch 51/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1079 - accuracy: 0.9165 - val_loss: 0.1066 - val_accuracy: 0.9182\n",
            "Epoch 52/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1075 - accuracy: 0.9168 - val_loss: 0.1050 - val_accuracy: 0.9168\n",
            "Epoch 53/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1079 - accuracy: 0.9166 - val_loss: 0.1099 - val_accuracy: 0.9182\n",
            "Epoch 54/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1074 - accuracy: 0.9166 - val_loss: 0.1090 - val_accuracy: 0.9159\n",
            "Epoch 55/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1073 - accuracy: 0.9173 - val_loss: 0.1096 - val_accuracy: 0.9166\n",
            "Epoch 56/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1075 - accuracy: 0.9168 - val_loss: 0.1051 - val_accuracy: 0.9180\n",
            "Epoch 57/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1074 - accuracy: 0.9172 - val_loss: 0.1066 - val_accuracy: 0.9184\n",
            "Epoch 58/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1074 - accuracy: 0.9163 - val_loss: 0.1072 - val_accuracy: 0.9171\n",
            "Epoch 59/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1076 - accuracy: 0.9166 - val_loss: 0.1063 - val_accuracy: 0.9170\n",
            "Epoch 60/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1073 - accuracy: 0.9172 - val_loss: 0.1074 - val_accuracy: 0.9172\n",
            "Epoch 61/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1072 - accuracy: 0.9178 - val_loss: 0.1050 - val_accuracy: 0.9191\n",
            "Epoch 62/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1070 - accuracy: 0.9171 - val_loss: 0.1051 - val_accuracy: 0.9178\n",
            "Epoch 63/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1071 - accuracy: 0.9176 - val_loss: 0.1060 - val_accuracy: 0.9193\n",
            "Epoch 64/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1068 - accuracy: 0.9173 - val_loss: 0.1032 - val_accuracy: 0.9198\n",
            "Epoch 65/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1071 - accuracy: 0.9173 - val_loss: 0.1063 - val_accuracy: 0.9172\n",
            "Epoch 66/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1067 - accuracy: 0.9178 - val_loss: 0.1104 - val_accuracy: 0.9133\n",
            "Epoch 67/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1067 - accuracy: 0.9171 - val_loss: 0.1076 - val_accuracy: 0.9183\n",
            "Epoch 68/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1068 - accuracy: 0.9174 - val_loss: 0.1029 - val_accuracy: 0.9187\n",
            "Epoch 69/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1065 - accuracy: 0.9172 - val_loss: 0.1048 - val_accuracy: 0.9179\n",
            "Epoch 70/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1069 - accuracy: 0.9168 - val_loss: 0.1151 - val_accuracy: 0.9111\n",
            "Epoch 71/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1068 - accuracy: 0.9180 - val_loss: 0.1052 - val_accuracy: 0.9169\n",
            "Epoch 72/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1062 - accuracy: 0.9178 - val_loss: 0.1091 - val_accuracy: 0.9195\n",
            "Epoch 73/74\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.1064 - accuracy: 0.9175 - val_loss: 0.1045 - val_accuracy: 0.9186\n",
            "Epoch 74/74\n",
            "2500/2500 [==============================] - 6s 3ms/step - loss: 0.1063 - accuracy: 0.9183 - val_loss: 0.1068 - val_accuracy: 0.9163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb82df2c090>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel.fit(X, Y_norm, epochs=100, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "hY0I_oikhQEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "scores = hypermodel.evaluate(X, Y_norm, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9WFFUZ7Zj_b",
        "outputId": "7b703962-b040-48eb-bdc3-f0e565598b51"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 91.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X)\n",
        "    #plt.scatter(Y[:,0], predictions[:,0], color='red')\n",
        "  #plt.scatter(Y[:,1], predictions[:,1], color='blue')\n",
        "  #plt.show()"
      ],
      "metadata": {
        "id": "jibVM0hkxgEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=unnormalize_y(predictions, mu1, sigma1, mu2, sigma2)\n",
        "pred[:,1]"
      ],
      "metadata": {
        "id": "Er4z2cgRyx1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y[:,1]"
      ],
      "metadata": {
        "id": "lhTdnEBsy3sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mu1, sigma1, mu2, sigma2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45iqD-Ot9GJJ",
        "outputId": "037dd2b2-73ab-4172-f39f-aed28995fb5c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25319026504505765 0.0870925635266098 16.48226262676655 3.472243709346458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = \"DFDQVPDDPLLVLLLVVLLVVDDLVVSCVVVVHHSVVSVVSVVVSCVRRVQPDSPSSNVVCVVVVPD\"\n",
        "feats = []\n",
        "counts1mer = add_1mer_counts(seq)\n",
        "feats.append(np.append(counts1mer, [len(seq)]))\n",
        "pred = hypermodel.predict(np.asarray(feats))\n",
        "pred_norm = unnormalize_y(pred, mu1, sigma1, mu2, sigma2)\n",
        "#print(pred_norm)\n",
        "\n",
        "from math import exp, log\n",
        "# compute pvalue from score using evd with mu lambda\n",
        "def compute_pvalue(score, lambda_, mu):\n",
        "    h = lambda_ * (score - mu)\n",
        "    if h > 10:\n",
        "      return -h \n",
        "    elif h < -2.5:\n",
        "      return -exp(-exp(-h)) \n",
        "    else:\n",
        "      return log((1.0 - exp(-exp(-h))))\n",
        "\n",
        "logPval = compute_pvalue(84, pred_norm[0][0], pred_norm[0][1])\n",
        "#logPval = compute_pvalue(80, 0.169, 18.92)\n",
        "print(exp(logPval + log(9330577)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_quXHddN5v8",
        "outputId": "fdf665e1-5be1-4059-bba1-c4d1ae1736b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0005788370215863978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/moof2k/kerasify/master/kerasify.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W72O9KfQLif",
        "outputId": "c9425b67-730a-40e7-91b9-fdddd891c411"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-19 05:21:21--  https://raw.githubusercontent.com/moof2k/kerasify/master/kerasify.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7789 (7.6K) [text/plain]\n",
            "Saving to: ‘kerasify.py’\n",
            "\n",
            "kerasify.py         100%[===================>]   7.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-19 05:21:22 (102 MB/s) - ‘kerasify.py’ saved [7789/7789]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerasify import export_model\n",
        "export_model(hypermodel, '/content/drive/MyDrive/100k_per_query_mu_lambda.kerasify.model')"
      ],
      "metadata": {
        "id": "14n4jhHIVi6c"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}