{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6dee73-de73-478e-bbb7-1d40169590d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport homstrad_util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b71b0-2d59-4c7e-8dc1-ac00ca8977b6",
   "metadata": {},
   "source": [
    "# Split PDB chains into single PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f325c-8e00-47e1-b311-247226e0bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for family in tqdm(os.listdir('homstrad_db/')):\n",
    "    os.makedirs(f'out/pdbs/{family}', exist_ok=True)\n",
    "    \n",
    "    # Parse family member names\n",
    "    with open(f'homstrad_db/{family}/{family}.ali') as file:\n",
    "        fam_members = []\n",
    "        for line in file:\n",
    "            if line.startswith('>'):\n",
    "                name = line[4:-1]\n",
    "                fam_members.append(name)\n",
    "                assert len(name) != 0, f'{fam_members[-1]} is to short'\n",
    "        \n",
    "    \n",
    "    # Split family PDB\n",
    "    chains = ''  # \n",
    "    with open(f'homstrad_db/{family}/{family}-sup.pdb') as file:\n",
    "        single_pdbs = [[] for _ in fam_members]\n",
    "        last_chain = None\n",
    "        i = -1\n",
    "        for line in file:\n",
    "            if line.startswith('ATOM'):\n",
    "                chain = line[21:22]\n",
    "                if chain != last_chain:\n",
    "                    i += 1\n",
    "                    last_chain = chain\n",
    "                    chains += chain\n",
    "                assert i >= 0\n",
    "                single_pdbs[i].append(line)\n",
    "\n",
    "    assert len(chains) == len(single_pdbs)\n",
    "                \n",
    "    # Find mapping between alignment and pdb file\n",
    "    with open(f'homstrad_db/{family}/{family}-sup.pdb') as file:\n",
    "        pdb_txt = file.read()\n",
    "    # mapping is contained in remark section of pdb file\n",
    "    if 'REMARK The domains in this file are:' in pdb_txt:\n",
    "        lines = pdb_txt.splitlines()\n",
    "        idx = lines.index([line for line in lines if line.startswith('REMARK The domains in this file are:')][0])\n",
    "        id2chain = {}\n",
    "        for line in lines[idx+1:idx+1+len(fam_members)]:\n",
    "            _, name, chain, chain_name = line.split()\n",
    "            assert chain == 'chain'\n",
    "            id2chain[name] = chain_name\n",
    "\n",
    "        \n",
    "    # Extract all pdbs\n",
    "    if 'REMARK The domains in this file are:' in pdb_txt:\n",
    "        pdbs_ordered = [single_pdbs[chains.index(id2chain[name])] for name in fam_members]\n",
    "    else:\n",
    "        pdbs_ordered = single_pdbs\n",
    "    for lines, name in zip(pdbs_ordered, fam_members):\n",
    "        assert len(lines) > 0\n",
    "        os.makedirs(f'out/hmstrd_pdbs/{family}', exist_ok=True)\n",
    "        with open(f'out/hmstrd_pdbs/{family}/{name}.pdb', 'w') as pdb_file:\n",
    "            pdb_file.writelines(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea0af4-5a3e-42d5-8a74-5db17e057cef",
   "metadata": {},
   "source": [
    "# Run DALI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6809b1b-702a-4613-85bd-2acb4727d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run_dali.sh\n",
    "#!/bin/bash\n",
    "\n",
    "DALIBIN=$(realpath $1)\n",
    "FAMDIR=$2\n",
    "\n",
    "rm -rf \"$FAMDIR\"/dali_tmp\n",
    "mkdir -p \"$FAMDIR\"/dali_tmp/DAT\n",
    "mkdir -p \"$FAMDIR\"/dali_tmp/out\n",
    "\n",
    "# Import pdbs into Dali0\n",
    "for name in \"$FAMDIR\"/*.pdb\n",
    "do    \n",
    "    BN=\"${name##*/}\";\n",
    "    \"$DALIBIN\"/import.pl --pdbfile $name --pdbid \"${BN:0:4}\" --clean --dat \"$FAMDIR\"/dali_tmp/DAT >> \"$FAMDIR\"/dali_tmp/log.txt 2>&1\n",
    "done\n",
    "\n",
    "# Create list of imported pdbs\n",
    "for name in \"$FAMDIR\"/dali_tmp/DAT/*.dat\n",
    "do    \n",
    "    BN=\"${name##*/}\";\n",
    "    echo \"${BN:0:5}\" >> \"$FAMDIR\"/dali_tmp/ids.txt\n",
    "done\n",
    "\n",
    "cd \"$FAMDIR\"/dali_tmp/out\n",
    "\"$DALIBIN\"/dali.pl --query ../ids.txt --matrix --dat1 ../DAT --clean --outfmt \"summary,alignments\" >> ../log.txt 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd39086-0afc-4bb2-a643-9a12fa0ba535",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x run_dali.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d59800-ba11-4f84-bb2b-e92942056334",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fam in os.listdir('out/hmstrd_pdbs/'):\n",
    "    path = f'out/hmstrd_pdbs/{fam}'\n",
    "    !./run_dali.sh out/DaliLite.v5/bin {path}\n",
    "    print('>'*10, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a86a03-faae-4ccc-96ef-7777ecdfb8f7",
   "metadata": {},
   "source": [
    "## Parse Dali output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b42e7-9cd5-4753-94fd-5e9602828670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dali_aln(aln1, aln2):\n",
    "    assert len(aln1) == len(aln2)\n",
    "    res1, res2 = '', ''\n",
    "    buffer1, buffer2 = '', ''\n",
    "    for c1, c2 in zip(aln1, aln2):\n",
    "        if c1.islower() and c2.islower():\n",
    "            #res1 += '-' + c1\n",
    "            #res2 += c2 + '-'\n",
    "            buffer1 += c1\n",
    "            buffer2 += c2\n",
    "        else:\n",
    "            if buffer1:\n",
    "                res1 += buffer1 + ('-' * len(buffer1))\n",
    "                res2 += ('-' * len(buffer2)) + buffer2\n",
    "                buffer1, buffer2 = '', ''\n",
    "            res1 += c1\n",
    "            res2 += c2\n",
    "\n",
    "    if buffer1:\n",
    "        res1 += buffer1 + ('-' * len(buffer1))\n",
    "        res2 += ('-' * len(buffer2)) + buffer2\n",
    "        buffer1, buffer2 = '', ''\n",
    "    return res1, res2\n",
    "\n",
    "def read_chain_name(family, name):\n",
    "    with open(f'out/hmstrd_pdbs/{family}/{name}.pdb') as file:\n",
    "        return file.readline().split()[4][:1]\n",
    "\n",
    "def recover_name(family, dali_id):\n",
    "    \"\"\"Dali takes only the first 4 letters from the HOMSTRDA pdb names *and* appends the chain in the output.\"\"\"\n",
    "    # Read the original names \n",
    "    ref_aln = homstrad_util.parse_homstrad_ali(f'homstrad_db/{family}/{family}.ali')\n",
    "    ref_names = [i[0] for i in ref_aln]\n",
    "\n",
    "    # Find canditates where the first letters match\n",
    "    hits = [n for n in ref_names if n.startswith(dali_id[:4])]\n",
    "    if len(hits) == 1:\n",
    "        return hits[0]\n",
    "    else:\n",
    "        # Additionally lookup the chain names in the pdb files\n",
    "        chain_names = [read_chain_name(family, hit) for hit in hits]\n",
    "        try:\n",
    "            idx = chain_names.index(dali_id[4])\n",
    "        except ValueError:\n",
    "            print(f'dali_id: {dali_id}, hits: {hits}')\n",
    "            raise\n",
    "        return hits[idx]\n",
    "\n",
    "def parse_dali(root_dir, family, query):\n",
    "    # Locate result file\n",
    "    dali_out = f'{root_dir}/{family}/dali_tmp/out'\n",
    "    cand = glob(f'{dali_out}/{query}*.txt')\n",
    "    if not cand:\n",
    "        chain = read_chain_name(family, query)\n",
    "        cand = glob(f'{dali_out}/{query[:4] + chain}*.txt')\n",
    "    assert len(cand) == 1, f'{query} <-> {cand}'\n",
    "\n",
    "    with open(cand[0]) as dali_output:\n",
    "        txt = dali_output.read()\n",
    "\n",
    "    # Split by target\n",
    "    alignments = txt.split('No ')[1:]\n",
    "\n",
    "    output = []\n",
    "    for aln in alignments:\n",
    "        lines = aln.splitlines()\n",
    "        header = lines[0].split()\n",
    "        qname, tname = header[1].split('=')[1], header[2].split('=')[1]\n",
    "        qaln, taln = '', ''\n",
    "        for line in lines:\n",
    "            if line.startswith('Query'):\n",
    "                qaln += line.split()[1]\n",
    "            if line.startswith('Sbjct'):\n",
    "                taln += line.split()[1]\n",
    "\n",
    "        qaln, taln = normalize_dali_aln(qaln, taln)\n",
    "        qname = recover_name(family, qname)\n",
    "        tname = recover_name(family, tname)\n",
    "\n",
    "        output.append(f'{qname} {tname} 0 0 {qaln} {taln}')\n",
    "        \n",
    "    # Write result\n",
    "    with open(f'{root_dir}/{family}/dali.aln', 'w') as file:\n",
    "        file.write('\\n'.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b9e1d-2a21-4093-aa76-530614e4af18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fam in os.listdir('out/hmstrd_pdbs/'):\n",
    "    query = homstrad_util.parse_homstrad_ali(f'homstrad_db/{fam}/{fam}.ali')[0][0]\n",
    "    try:\n",
    "        parse_dali('out/hmstrd_pdbs/', fam, query)\n",
    "    except AssertionError as e:\n",
    "        print(fam, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b99805-e369-46f4-8ff7-f9bf3114604d",
   "metadata": {},
   "source": [
    "# Run Foldseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb1300-8863-46f6-bdb6-dd03a1662dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run_foldseek.sh\n",
    "#!/bin/bash\n",
    "\n",
    "FOLDSEEK=\"$1\"\n",
    "FAMDIR=\"$2\"\n",
    "\n",
    "rm -rf \"$FAMDIR\"/foldseek_tmp\n",
    "mkdir -p \"$FAMDIR\"/foldseek_tmp\n",
    "\n",
    "$FOLDSEEK easy-search \"$FAMDIR\" \"$FAMDIR\" \"$FAMDIR\"/foldseek_tmp/result.tsv out/tmp/ \\\n",
    "    --exhaustive-search -e 100000 -a --format-output \"query,target,qstart,tstart,qaln,taln,evalue,bits\" >> \"$FAMDIR\"/foldseek_tmp/log.txt 2>&1\n",
    "\n",
    "awk '{split($1, name1, \".\"); split($2, name2, \".\"); print name1[1], name2[1], $3-1, $4-1, $5, $6}' \"$FAMDIR\"/foldseek_tmp/result.tsv > \"$FAMDIR\"/foldseek.aln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e9d36-1ad2-4029-8215-b2813549c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x run_foldseek.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45308391-1830-4e19-9142-1ac4c767055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fam in os.listdir('out/hmstrd_pdbs/'):\n",
    "    path = f'out/hmstrd_pdbs/{fam}'\n",
    "    !./run_foldseek.sh ../../../git/foldseek/build/src/foldseek {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485a31e-564c-465a-9231-8fe93135c95b",
   "metadata": {},
   "source": [
    "# Generate 3Di sequences for each family (AA sequence are in alignment file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4aacbb-d64d-4e8f-8c72-827fa2f0728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out out\n",
    "\n",
    "FOLDSEEK=../../../git/foldseek/build/src/foldseek\n",
    "\n",
    "rm -f out/db*\n",
    "\n",
    "for fam in out/hmstrd_pdbs/*\n",
    "do\n",
    "    $FOLDSEEK createdb $fam out/db\n",
    "    $FOLDSEEK lndb out/db_h out/db_ss_h\n",
    "    $FOLDSEEK convert2fasta out/db_ss $fam/ss.fasta\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
