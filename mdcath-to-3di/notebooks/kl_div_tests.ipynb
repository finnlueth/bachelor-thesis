{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[-0.8394,  1.6679,  0.5327],\n",
      "        [ 0.5723,  0.3403, -1.8713],\n",
      "        [ 0.7562,  0.2992,  0.8017],\n",
      "        [ 0.0177, -0.0691, -0.6578],\n",
      "        [-0.6957,  1.6073,  0.4324]], requires_grad=True)\n",
      "torch.Size([5, 3])\n",
      "tensor([[0.0891, 0.2255, 0.6854],\n",
      "        [0.3820, 0.4924, 0.1256],\n",
      "        [0.2391, 0.6474, 0.1135],\n",
      "        [0.1500, 0.3117, 0.5384],\n",
      "        [0.1093, 0.7942, 0.0965]])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(5, 3, requires_grad=True)\n",
    "target_tensor = torch.randn(5, 3)\n",
    "\n",
    "target_tensor = F.softmax(target_tensor, dim=1)\n",
    "print(input_tensor.shape)\n",
    "print(input_tensor)\n",
    "print(target_tensor.shape)\n",
    "print(target_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor torch.Size([2, 5, 3])\n",
      "tensor([[[ 0.6677,  1.0659, -2.6843],\n",
      "         [-1.7150, -0.6264,  1.6480],\n",
      "         [ 0.1499,  0.9312, -0.8252],\n",
      "         [-0.0703,  2.6022,  0.8705],\n",
      "         [-0.2852, -1.4555, -0.5974]],\n",
      "\n",
      "        [[ 1.3257, -1.1151,  0.1241],\n",
      "         [-3.5583,  0.1384, -0.6323],\n",
      "         [-0.2360, -0.1520, -0.3012],\n",
      "         [ 0.6702,  0.7576,  1.5766],\n",
      "         [-0.8387, -0.0367, -0.5284]]])\n",
      "target_tensor torch.Size([2, 5, 3])\n",
      "tensor([[[     0.3662,      0.3598,      0.2739],\n",
      "         [     0.5289,      0.2933,      0.1778],\n",
      "         [     0.8479,      0.0478,      0.1043],\n",
      "         [  -100.0000,   -100.0000,   -100.0000],\n",
      "         [  -100.0000,   -100.0000,   -100.0000]],\n",
      "\n",
      "        [[     0.0752,      0.8602,      0.0647],\n",
      "         [     0.3488,      0.2728,      0.3784],\n",
      "         [     0.8237,      0.1216,      0.0547],\n",
      "         [     0.1242,      0.7966,      0.0792],\n",
      "         [  -100.0000,   -100.0000,   -100.0000]]])\n",
      "input_tensor torch.Size([10, 3])\n",
      "tensor([[ 0.6677,  1.0659, -2.6843],\n",
      "        [-1.7150, -0.6264,  1.6480],\n",
      "        [ 0.1499,  0.9312, -0.8252],\n",
      "        [-0.0703,  2.6022,  0.8705],\n",
      "        [-0.2852, -1.4555, -0.5974],\n",
      "        [ 1.3257, -1.1151,  0.1241],\n",
      "        [-3.5583,  0.1384, -0.6323],\n",
      "        [-0.2360, -0.1520, -0.3012],\n",
      "        [ 0.6702,  0.7576,  1.5766],\n",
      "        [-0.8387, -0.0367, -0.5284]])\n",
      "target_tensor torch.Size([10, 3])\n",
      "tensor([[     0.3662,      0.3598,      0.2739],\n",
      "        [     0.5289,      0.2933,      0.1778],\n",
      "        [     0.8479,      0.0478,      0.1043],\n",
      "        [  -100.0000,   -100.0000,   -100.0000],\n",
      "        [  -100.0000,   -100.0000,   -100.0000],\n",
      "        [     0.0752,      0.8602,      0.0647],\n",
      "        [     0.3488,      0.2728,      0.3784],\n",
      "        [     0.8237,      0.1216,      0.0547],\n",
      "        [     0.1242,      0.7966,      0.0792],\n",
      "        [  -100.0000,   -100.0000,   -100.0000]])\n",
      "\n",
      " ********************Masking******************** \n",
      "\n",
      "tensor([ True,  True,  True, False, False,  True,  True,  True,  True, False])\n",
      "input_tensor torch.Size([7, 3])\n",
      "tensor([[0.3962, 0.5900, 0.0139],\n",
      "        [0.0304, 0.0904, 0.8791],\n",
      "        [0.2808, 0.6133, 0.1059],\n",
      "        [0.7206, 0.0628, 0.2167],\n",
      "        [0.0167, 0.6723, 0.3111],\n",
      "        [0.3306, 0.3596, 0.3098],\n",
      "        [0.2190, 0.2390, 0.5421]])\n",
      "target_tensor torch.Size([7, 3])\n",
      "tensor([[0.3662, 0.3598, 0.2739],\n",
      "        [0.5289, 0.2933, 0.1778],\n",
      "        [0.8479, 0.0478, 0.1043],\n",
      "        [0.0752, 0.8602, 0.0647],\n",
      "        [0.3488, 0.2728, 0.3784],\n",
      "        [0.8237, 0.1216, 0.0547],\n",
      "        [0.1242, 0.7966, 0.0792]])\n",
      "\n",
      " ********************KL Div 1******************** \n",
      "\n",
      "tensor(1.0212)\n",
      "\n",
      " ********************KL Div 2******************** \n",
      "\n",
      "tensor(0.9249)\n",
      "tensor(1.9462)\n"
     ]
    }
   ],
   "source": [
    "# [batch, seq_len, hidden_size]\n",
    "\n",
    "input_tensor = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [0.6677, 1.0659, -2.6843],\n",
    "            [-1.7150, -0.6264, 1.6480],\n",
    "            [0.1499, 0.9312, -0.8252],\n",
    "            [-0.0703, 2.6022, 0.8705],\n",
    "            [-0.2852, -1.4555, -0.5974],\n",
    "        ],\n",
    "        [\n",
    "            [1.3257, -1.1151, 0.1241],\n",
    "            [-3.5583, 0.1384, -0.6323],\n",
    "            [-0.2360, -0.1520, -0.3012],\n",
    "            [0.6702, 0.7576, 1.5766],\n",
    "            [-0.8387, -0.0367, -0.5284],\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "target_tensor = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [0.3662, 0.3598, 0.2739],\n",
    "            [0.5289, 0.2933, 0.1778],\n",
    "            [0.8479, 0.0478, 0.1043],\n",
    "            [-100, -100, -100],\n",
    "            [-100, -100, -100],\n",
    "        ],\n",
    "        [\n",
    "            [0.0752, 0.8602, 0.0647],\n",
    "            [0.3488, 0.2728, 0.3784],\n",
    "            [0.8237, 0.1216, 0.0547],\n",
    "            [0.1242, 0.7966, 0.0792],\n",
    "            [-100, -100, -100],\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"input_tensor\", input_tensor.shape)\n",
    "print(input_tensor)\n",
    "print(\"target_tensor\", target_tensor.shape)\n",
    "print(target_tensor)\n",
    "\n",
    "input_tensor = input_tensor.flatten(end_dim=1)\n",
    "target_tensor = target_tensor.flatten(end_dim=1)\n",
    "\n",
    "\n",
    "print(\"input_tensor\", input_tensor.shape)\n",
    "print(input_tensor)\n",
    "print(\"target_tensor\", target_tensor.shape)\n",
    "print(target_tensor)\n",
    "\n",
    "print(\"\\n\", \"*\" * 20 + \"Masking\" + \"*\" * 20, \"\\n\")\n",
    "\n",
    "mask = None\n",
    "if mask is None:\n",
    "    mask = ~torch.any(target_tensor == -100, dim=1)\n",
    "\n",
    "print(mask)\n",
    "\n",
    "input_tensor = input_tensor[mask]\n",
    "target_tensor = target_tensor[mask]\n",
    "\n",
    "input_tensor = F.softmax(input_tensor, dim=1)\n",
    "print(\"input_tensor\", input_tensor.shape)\n",
    "print(input_tensor)\n",
    "print(\"target_tensor\", target_tensor.shape)\n",
    "print(target_tensor)\n",
    "\n",
    "\n",
    "kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "print(\"\\n\", \"*\" * 20 + \"KL Div 1\" + \"*\" * 20, \"\\n\")\n",
    "output_1 = kl_loss(torch.log(input_tensor), target_tensor)\n",
    "print(output_1)\n",
    "\n",
    "print(\"\\n\", \"*\" * 20 + \"KL Div 2\" + \"*\" * 20, \"\\n\")\n",
    "output_2 = kl_loss(torch.log(target_tensor), input_tensor)\n",
    "print(output_2)\n",
    "\n",
    "\n",
    "print(output_1 + output_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor(1.0687)\n",
    "tensor(0.9326)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6677,  1.0659, -2.6843],\n",
      "         [-1.7150, -0.6264,  1.6480],\n",
      "         [ 0.1499,  0.9312, -0.8252],\n",
      "         [-0.0703,  2.6022,  0.8705],\n",
      "         [-0.2852, -1.4555, -0.5974]],\n",
      "\n",
      "        [[ 1.3257, -1.1151,  0.1241],\n",
      "         [-3.5583,  0.1384, -0.6323],\n",
      "         [-0.2360, -0.1520, -0.3012],\n",
      "         [ 0.6702,  0.7576,  1.5766],\n",
      "         [-0.8387, -0.0367, -0.5284]]])\n",
      "tensor([[[     0.3662,      0.3598,      0.2739],\n",
      "         [     0.5289,      0.2933,      0.1778],\n",
      "         [     0.8479,      0.0478,      0.1043],\n",
      "         [  -100.0000,   -100.0000,   -100.0000],\n",
      "         [  -100.0000,   -100.0000,   -100.0000]],\n",
      "\n",
      "        [[     0.0752,      0.8602,      0.0647],\n",
      "         [     0.3488,      0.2728,      0.3784],\n",
      "         [     0.8237,      0.1216,      0.0547],\n",
      "         [     0.1242,      0.7966,      0.0792],\n",
      "         [  -100.0000,   -100.0000,   -100.0000]]])\n",
      "\n",
      "tensor([[0.3962, 0.5900, 0.0139],\n",
      "        [0.0304, 0.0904, 0.8791],\n",
      "        [0.2808, 0.6133, 0.1059],\n",
      "        [0.7206, 0.0628, 0.2167],\n",
      "        [0.0167, 0.6723, 0.3111],\n",
      "        [0.3306, 0.3596, 0.3098],\n",
      "        [0.2190, 0.2390, 0.5421]])\n",
      "tensor([[0.3662, 0.3598, 0.2739],\n",
      "        [0.5289, 0.2933, 0.1778],\n",
      "        [0.8479, 0.0478, 0.1043],\n",
      "        [0.0752, 0.8602, 0.0647],\n",
      "        [0.3488, 0.2728, 0.3784],\n",
      "        [0.8237, 0.1216, 0.0547],\n",
      "        [0.1242, 0.7966, 0.0792]])\n",
      "\n",
      "tensor(1.0212)\n",
      "tensor(0.9249)\n",
      "tensor(1.9462)\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [0.6677, 1.0659, -2.6843],\n",
    "            [-1.7150, -0.6264, 1.6480],\n",
    "            [0.1499, 0.9312, -0.8252],\n",
    "            [-0.0703, 2.6022, 0.8705],\n",
    "            [-0.2852, -1.4555, -0.5974],\n",
    "        ],\n",
    "        [\n",
    "            [1.3257, -1.1151, 0.1241],\n",
    "            [-3.5583, 0.1384, -0.6323],\n",
    "            [-0.2360, -0.1520, -0.3012],\n",
    "            [0.6702, 0.7576, 1.5766],\n",
    "            [-0.8387, -0.0367, -0.5284],\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "labels = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [0.3662, 0.3598, 0.2739],\n",
    "            [0.5289, 0.2933, 0.1778],\n",
    "            [0.8479, 0.0478, 0.1043],\n",
    "            [-100, -100, -100],\n",
    "            [-100, -100, -100],\n",
    "        ],\n",
    "        [\n",
    "            [0.0752, 0.8602, 0.0647],\n",
    "            [0.3488, 0.2728, 0.3784],\n",
    "            [0.8237, 0.1216, 0.0547],\n",
    "            [0.1242, 0.7966, 0.0792],\n",
    "            [-100, -100, -100],\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(logits)\n",
    "print(labels)\n",
    "print()\n",
    "\n",
    "logits = F.softmax(logits, dim=2)\n",
    "\n",
    "tensor_truth = labels.flatten(end_dim=1)\n",
    "tensor_pred = logits.flatten(end_dim=1)\n",
    "\n",
    "# tensor_pred = F.softmax(tensor_pred, dim=1)\n",
    "\n",
    "mask = None\n",
    "if mask is None:\n",
    "    mask = ~torch.any(tensor_truth == -100, dim=1)\n",
    "\n",
    "tensor_pred = tensor_pred[mask]\n",
    "tensor_truth = tensor_truth[mask]\n",
    "\n",
    "print(tensor_pred)\n",
    "print(tensor_truth)\n",
    "print()\n",
    "\n",
    "loss_fct = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "loss_1 = loss_fct(torch.log(tensor_pred), tensor_truth)\n",
    "loss_2 = loss_fct(torch.log(tensor_truth), tensor_pred)\n",
    "\n",
    "loss = loss_1 + loss_2\n",
    "\n",
    "print(loss_1)\n",
    "print(loss_2)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collated_dataset = data_collator(features=dataset)\n",
    "\n",
    "# collated_dataset[\"input_ids\"]\n",
    "\n",
    "# attention_mask = collated_dataset[\"attention_mask\"]\n",
    "# mask = attention_mask.unsqueeze(1).float()\n",
    "\n",
    "# print(mask.shape)\n",
    "# print(mask)\n",
    "# print(*[\"-\" * 100] * 10, sep=\"\\n\")\n",
    "# print(attention_mask.shape)\n",
    "# print(attention_mask)\n",
    "\n",
    "# mask * torch.randn(8, 360, 1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
