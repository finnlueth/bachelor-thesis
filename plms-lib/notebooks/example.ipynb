{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from plms.configurations.configuration_base_plm import PLMConfig\n",
    "from plms.models import auto_model, auto_tokenizer\n",
    "from plms.models.T5.modeling_protT5 import ProtT5\n",
    "from plms.models.T5.tokenization_protT5 import ProtT5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"Rostlab/prot_t5_xl_uniref50\"\n",
    "model_name = \"Rostlab/ProstT5\"\n",
    "\n",
    "tokenizer = auto_tokenizer(model_name)\n",
    "# Or for more explicity:\n",
    "# tokenizer = ProtT5Tokenizer(name_or_path=\"Rostlab/prot_t5_xl_uniref50\")\n",
    "\n",
    "\n",
    "model = auto_model(model_name=model_name)\n",
    "# Or for more explicity:\n",
    "# model = ProtT5(name_or_path=\"Rostlab/prot_t5_xl_uniref50\")\n",
    "# Or with a config:\n",
    "# config=PLMConfig(name_or_path=\"Rostlab/prot_t5_xl_uniref50\")\n",
    "# model = ProtT5(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 3   22  10  9   15  5   20  12  14  4   19  17  13  16  8   7   11  6   21  18  23  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "149 3   22  10  9   15  5   20  12  14  4   19  17  13  16  8   7   11  6   21  18  23  3   22  10  9   15  5   20  12  14  4   19  17  13  16  8   7   11  6   21  18  23  1   \n",
      "1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   \n",
      "148 128 147 135 134 140 130 145 137 139 129 144 142 138 141 133 132 136 131 146 143 1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n"
     ]
    }
   ],
   "source": [
    "sequence_fasta = \"\"\">seq1\n",
    "ACDEFGHIKLMNPQRSTVWY\n",
    "ACDEFGHIKLMNPQRSTVWY\n",
    "ACDEFGHIKLMNPQRSTVWY\n",
    "ACDEFGHIKLMNPQRSTVWY\n",
    ">seq2\n",
    "ACDEFGHIKLMNPQRSTVWY\n",
    ">seq3\n",
    "acdefghiklmnpqrstvwy\n",
    "acdefghiklmnpqrstvwy\n",
    "\"\"\"\n",
    "sequence_strings = [\"ACDEFGHIKLMNPQRSTVWYO\", \"ACDEFGHIKLMNPQRSTVWYOACDEFGHIKLMNPQRSTVWYO\", \"acdefghiklmnpqrstvwyo\"]\n",
    "\n",
    "# tokenizer_output = tokenizer.tokenize_fasta(\n",
    "#     \"../../prot-md-pssm-benchmark/scope-benchmark-minimal/data/scope40_sequences_aa_short.fasta\",\n",
    "#     padding=True,\n",
    "# )\n",
    "# tokenizer_output = tokenizer.tokenize_fasta(fasta=sequence_fasta, return_headers=True)\n",
    "tokenizer_output = tokenizer.encode(sequence_strings, padding=True)\n",
    "\n",
    "\n",
    "for ids, mask in zip(tokenizer_output[\"input_ids\"], tokenizer_output[\"attention_mask\"]):\n",
    "    print(*[f\"{x:<4d}\" for x in ids], sep=\"\")\n",
    "    print(*[f\"{x:<4d}\" for x in mask], sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 3   22  10  9   15  5   20  12  14  4   19  17  13  16  8   7   11  6   21  18  23  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "A   C   D   E   F   G   H   I   K   L   M   N   P   Q   R   S   T   V   W   Y   X  \n",
      "\n",
      "149 3   22  10  9   15  5   20  12  14  4   19  17  13  16  8   7   11  6   21  18  23  3   22  10  9   15  5   20  12  14  4   19  17  13  16  8   7   11  6   21  18  23  1  \n",
      "1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  \n",
      "A   C   D   E   F   G   H   I   K   L   M   N   P   Q   R   S   T   V   W   Y   X   A   C   D   E   F   G   H   I   K   L   M   N   P   Q   R   S   T   V   W   Y   X  \n",
      "\n",
      "148 128 147 135 134 140 130 145 137 139 129 144 142 138 141 133 132 136 131 146 143 1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      "a   c   d   e   f   g   h   i   k   l   m   n   p   q   r   s   t   v   w   y  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer_output[\"input_ids\"]\n",
    "attention_mask = tokenizer_output[\"attention_mask\"]\n",
    "decoded_tokens = tokenizer.decode(input_ids)\n",
    "for i, m, d in zip(input_ids, attention_mask, decoded_tokens):\n",
    "    print(*[str(x)[:4].ljust(3) for x in i], sep=\" \")\n",
    "    print(*[str(x)[:4].ljust(3) for x in m], sep=\" \")\n",
    "    print(*[str(x)[:4].ljust(3) for x in d], sep=\" \")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 3   22  10  9   15  5   20  12  14  4   19  17  13  16  8   7   11  6   21  18  23  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "149 3   22  10  9   15  5   20  12  14  4   19  17  13  16  8   7   11  6   21  18  23  3   22  10  9   15  5   20  12  14  4   19  17  13  16  8   7   11  6   21  18  23  1   \n",
      "1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   \n",
      "148 128 147 135 134 140 130 145 137 139 129 144 142 138 141 133 132 136 131 146 143 1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "\n",
      "torch.Size([3, 43])\n",
      "3     22    10    9     15    5     20    12    14    4     19    17    13    16    8     7     11    6     21    18    23    1     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     \n",
      "1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     \n",
      "186.8 193.8 233.8 163.4 173.4 177.9 161.8 181.1 170.7 168.4 159.3 200.0 174.2 141.7 173.2 180.3 173.9 214.2 219.6 184.9 53.5  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "3     22    10    9     15    5     20    12    14    4     19    17    13    16    8     7     11    6     21    18    23    3     22    10    9     15    5     20    12    14    4     19    17    13    16    8     7     11    6     21    18    23    1     \n",
      "1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     0     \n",
      "208.9 202.4 221.7 157.4 166.9 184.3 167.6 173.8 158.6 168.0 154.1 201.5 167.4 144.8 155.3 174.1 155.6 167.5 181.2 162.6 59.3  167.9 194.7 213.0 165.8 191.2 190.4 175.6 195.4 180.8 189.9 176.2 211.0 198.1 167.8 187.8 201.2 188.1 207.7 214.6 183.1 50.4  0.0   \n",
      "128   147   135   134   140   130   145   137   139   129   144   142   138   141   133   132   136   131   146   143   1     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     \n",
      "1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     1     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     \n",
      "188.5 166.1 150.6 171.7 270.6 166.2 157.8 284.4 244.1 165.2 237.5 141.0 143.8 135.7 128.1 135.3 165.5 134.0 159.8 147.4 0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model(\n",
    "        input_ids=torch.tensor(tokenizer_output[\"input_ids\"]).to(model.device),\n",
    "        attention_mask=torch.tensor(tokenizer_output[\"attention_mask\"]).to(model.device),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'mask'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acdefghiklmnpqrstvwyo\n",
      "1111111111111111111100000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "\n",
    "print(sequence_strings[index])\n",
    "print(*embeddings[\"mask\"][index].tolist(), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer_output[\"attention_mask\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer_output[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "df = pd.DataFrame(embeddings[\"last_hidden_state\"][index].cpu().numpy())\n",
    "df[\"sequence\"] = list(\n",
    "    \"-\" + sequence_strings[index] + (embeddings[\"last_hidden_state\"][index].shape[0] - len(sequence_strings[index]) - 1) * \"-\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plms.utils import modeling_utils\n",
    "\n",
    "for x in range(len(embeddings[\"last_hidden_state\"])):\n",
    "    print(\n",
    "        modeling_utils.mean_pool(\n",
    "            embeddings[\"last_hidden_state\"][x].unsqueeze(0),\n",
    "            embeddings[\"masks\"][x].unsqueeze(0),\n",
    "        ).mean()\n",
    "    )\n",
    "\n",
    "df_mean = modeling_utils.mean_pool(\n",
    "    embeddings[\"last_hidden_state\"],\n",
    "    embeddings[\"masks\"],\n",
    ")\n",
    "\n",
    "first = list(pd.DataFrame(df_mean.cpu().numpy()).iloc[0])\n",
    "second = list(embeddings[\"last_hidden_state\"][0].sum(dim=0) / embeddings[\"masks\"][0].sum(dim=0))\n",
    "\n",
    "print(first == second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
