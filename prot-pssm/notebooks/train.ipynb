{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import yaml\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from plm_pssms import PLMConfigForPSSM, PLMForPssmGeneration, DataCollatorForPSSM, ProteinSampleSubsetTrainer\n",
    "from plms import auto_tokenizer\n",
    "from transformers import TrainingArguments\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_identifier = 0\n",
    "temperature_identifier = \"all\"\n",
    "replica_identifier = 0\n",
    "\n",
    "config_yaml = f\"\"\"\n",
    "metadata:\n",
    "  name: \"prot-md-pssm\"\n",
    "  identifier: \n",
    "  run_name: temp-{temperature_identifier}_repl-{dataset_identifier}\n",
    "  save_dir: ../tmp/models/adapters\n",
    "model:\n",
    "#   encoder_name_or_path: Rostlab/prot_t5_xl_uniref50\n",
    "  encoder_name_or_path: Rostlab/ProstT5\n",
    "  hidden_size: 1024\n",
    "  num_labels: 20\n",
    "  dropout: 0.25\n",
    "training_args:\n",
    "  output_dir: ../tmp/models/checkpoints\n",
    "  learning_rate: 0.0001\n",
    "  per_device_train_batch_size: 10\n",
    "  per_device_eval_batch_size: 10\n",
    "  num_train_epochs: 1\n",
    "  logging_steps: 1\n",
    "  logging_strategy: steps\n",
    "  evaluation_strategy: steps\n",
    "  eval_steps: 1\n",
    "  eval_strategy: steps\n",
    "  eval_on_start: true\n",
    "  batch_eval_metrics: false\n",
    "  save_strategy: steps\n",
    "  save_steps: 300\n",
    "  save_total_limit: 5\n",
    "  remove_unused_columns: true\n",
    "  label_names: ['labels']\n",
    "  seed: 42\n",
    "  lr_scheduler_type: cosine\n",
    "  warmup_steps: 0\n",
    "  eval_sample_size: 10\n",
    "lora:\n",
    "  inference_mode: false\n",
    "  r: 8\n",
    "  lora_alpha: 16\n",
    "  lora_dropout: 0.05\n",
    "  use_rslora: false\n",
    "  use_dora: false\n",
    "  target_modules: ['q', 'v']\n",
    "  bias: none\n",
    "data_collator:\n",
    "  padding: true\n",
    "  pad_to_multiple_of: 8\n",
    "weights_and_biases:\n",
    "  enabled: true\n",
    "  project: prot-md-pssm\n",
    "dataset:\n",
    "  name: mdcath_pssm\n",
    "  identifier: _{dataset_identifier}\n",
    "  directory: ../tmp/data/pssm\n",
    "\"\"\"\n",
    "\n",
    "config = yaml.safe_load(config_yaml)\n",
    "\n",
    "identifier = (\n",
    "    config[\"metadata\"][\"name\"]\n",
    "    + \"_\"\n",
    "    + config[\"model\"][\"encoder_name_or_path\"].split(\"/\")[-1]\n",
    "    + \"_\"\n",
    "    + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    + (f\"_{config['metadata']['run_name'].replace(' ', '-')}\" if config[\"metadata\"][\"run_name\"] else \"\")\n",
    ")\n",
    "print(identifier)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "if config[\"weights_and_biases\"][\"enabled\"]:\n",
    "    import wandb\n",
    "\n",
    "    wandb.init(project=config[\"weights_and_biases\"][\"project\"], name=identifier)\n",
    "    run = wandb.init(project=config[\"weights_and_biases\"][\"project\"], name=identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_from_disk(f\"{config['dataset']['directory']}/{config['dataset']['name']}{config['dataset']['identifier']}\")\n",
    "ds = ds.rename_column(\"pssm_features\", \"labels\")\n",
    "\n",
    "if config[\"model\"][\"encoder_name_or_path\"] == \"Rostlab/ProstT5\":\n",
    "    ds = ds.remove_columns([\"input_ids_protT5\", \"attention_mask_protT5\"])\n",
    "    ds = ds.rename_column(\"input_ids_prostT5\", \"input_ids\")\n",
    "    ds = ds.rename_column(\"attention_mask_prostT5\", \"attention_mask\")\n",
    "if config[\"model\"][\"encoder_name_or_path\"] == \"Rostlab/prot_t5_xl_uniref50\":\n",
    "    ds = ds.remove_columns([\"input_ids_prostT5\", \"attention_mask_prostT5\"])\n",
    "    ds = ds.rename_column(\"input_ids_prostT5\", \"input_ids\")\n",
    "    ds = ds.rename_column(\"attention_mask_prostT5\", \"attention_mask\")\n",
    "\n",
    "ds = ds.remove_columns([\"name\", \"sequence\", \"replica\", \"temperature\"])\n",
    "# ds = ds.select(range(25))  # !!! TODO REMOVE THIS !!!\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = PLMConfigForPSSM(**config[\"model\"])\n",
    "model = PLMForPssmGeneration(model_config)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(**config[\"lora\"], modules_to_save=model.get_modules_to_save())\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(\"target_modules:\", lora_config.target_modules)\n",
    "print(\"modules_to_save:\", lora_config.modules_to_save)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = auto_tokenizer(config[\"model\"][\"encoder_name_or_path\"])\n",
    "\n",
    "data_collator = DataCollatorForPSSM(\n",
    "    tokenizer=tokenizer.get_tokenizer(),\n",
    "    padding=True,\n",
    "    pad_to_multiple_of=8,\n",
    ")\n",
    "\n",
    "\n",
    "class CustomTrainingArguments(TrainingArguments):\n",
    "    def __init__(self, eval_sample_size=32, **kwargs):\n",
    "        self.eval_sample_size = eval_sample_size\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "config[\"training_args\"][\"eval_sample_size\"] = config[\"training_args\"].get(\"eval_sample_size\", 32)\n",
    "\n",
    "training_args = CustomTrainingArguments(**config[\"training_args\"])\n",
    "\n",
    "trainer = ProteinSampleSubsetTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds,\n",
    "    eval_dataset=ds,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.reset_max_memory_allocated()\n",
    "        torch.cuda.reset_max_memory_cached()\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.mps.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_memory()\n",
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "clean_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = f\"{config['metadata']['save_dir']}/{identifier}\"\n",
    "\n",
    "model.save_pretrained(save_directory=model_save_path)\n",
    "\n",
    "pd.DataFrame(trainer.state.log_history).to_csv(f\"{model_save_path}/training_log.csv\", index=False)\n",
    "\n",
    "with open(f\"{model_save_path}/train_config.yaml\", \"w\") as f:\n",
    "    config[\"metadata\"][\"identifier\"] = identifier\n",
    "    yaml.dump(config, f, sort_keys=False)\n",
    "\n",
    "\n",
    "def plot_training_history(log_history, metrics_names=[\"loss\", \"eval_loss\"]):\n",
    "    plt.style.use(\"default\")\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    train_logs = log_history[log_history[\"loss\"].notna()]\n",
    "    eval_logs = log_history[log_history[\"eval_loss\"].notna()]\n",
    "\n",
    "    ax1.plot(train_logs[\"epoch\"], train_logs[\"loss\"], label=\"Training Loss\", color=\"orange\", linewidth=1)\n",
    "    ax1.plot(eval_logs[\"epoch\"], eval_logs[\"eval_loss\"], label=\"Eval Loss\", color=\"lightblue\", linewidth=1)\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"KL Divergence Loss\", color=\"blue\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.grid(True)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plot_training_history(log_history=pd.DataFrame(trainer.state.log_history), metrics_names=[\"loss\"])\n",
    "fig.savefig(f\"{model_save_path}/training_history.png\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Model, config, and log saved to:\", model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "scope40_seq_file_path = \"../tmp/data/scope40/scope40_sequences.json\"\n",
    "pssm_save_path = f\"../tmp/data/pssm_generated/{identifier}.tsv\"\n",
    "\n",
    "AA_ALPHABET = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\"]\n",
    "STRUCTURE_ALPHABET = [x.lower() for x in AA_ALPHABET]\n",
    "\n",
    "with open(scope40_seq_file_path, \"r\") as f:\n",
    "    scop_sequences = json.load(f)\n",
    "    # scop_sequences = dict(list(scop_sequences.items())[:111]) # !!! TODO REMOVE THIS !!!\n",
    "\n",
    "\n",
    "def pssm_to_csv(name, pssm):\n",
    "    df_pssm = pd.DataFrame(pssm)\n",
    "    df_pssm = df_pssm.round(4)\n",
    "\n",
    "    tsv_string = f\"Query profile of sequence {name}\\n\"\n",
    "    tsv_string += \"     \" + \"      \".join(AA_ALPHABET) + \"      \\n\"\n",
    "\n",
    "    df_string = df_pssm.to_csv(index=False, sep=\" \", float_format=\"%.4f\", header=False, lineterminator=\" \\n\")\n",
    "    tsv_string += df_string\n",
    "\n",
    "    return tsv_string\n",
    "\n",
    "\n",
    "batch_size = 50\n",
    "pssm_tsv = \"\"\n",
    "sequence_items = list(scop_sequences.items())\n",
    "sequence_batches = [dict(sequence_items[i : i + batch_size]) for i in range(0, len(sequence_items), batch_size)]\n",
    "\n",
    "if os.path.exists(pssm_save_path):\n",
    "    os.remove(pssm_save_path)\n",
    "\n",
    "model.eval()\n",
    "for batch in tqdm(sequence_batches, desc=\"Processing batches\"):\n",
    "    pssm_tsv = \"\"\n",
    "    protein_tokens = tokenizer.encode(list(batch.values()), return_tensors=\"pt\", padding=True, truncation=False).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(\n",
    "            input_ids=protein_tokens[\"input_ids\"],\n",
    "            attention_mask=protein_tokens[\"attention_mask\"],\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    for name, pssm, mask, ids in list(zip(batch.keys(), model_output.pssms, model_output.masks, protein_tokens[\"input_ids\"])):\n",
    "        pssm = pssm[mask.cpu().numpy().astype(bool)].cpu().numpy()\n",
    "        original_sequence = tokenizer.decode(ids, skip_special_tokens=True)\n",
    "        pssm_tsv += pssm_to_csv(name, pssm)\n",
    "\n",
    "    with open(pssm_save_path, \"a\") as f:\n",
    "        f.write(pssm_tsv)\n",
    "\n",
    "print(\"Created and appended PSSM to:\", pssm_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from contextlib import contextmanager\n",
    "import subprocess\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def working_directory(path):\n",
    "    \"\"\"Temporarily change working directory.\"\"\"\n",
    "    previous_dir = os.getcwd()\n",
    "    os.chdir(path)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        os.chdir(previous_dir)\n",
    "\n",
    "\n",
    "with working_directory(\"../benchmark\"):\n",
    "    print(\"Current working directory:\", os.getcwd())\n",
    "    benchmark_script = \"./runFoldseekMDPSSM.sh\"\n",
    "\n",
    "    print(f\"Running benchmark with dataset ID: {identifier}\")\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run([benchmark_script, identifier], check=True, text=True, capture_output=True)\n",
    "        print(\"Benchmark output:\")\n",
    "        print(result.stdout)\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Benchmark failed with error:\")\n",
    "        print(e.stderr)\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
